{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to generate a MinMaxScaler and Normalizer object on the entire data set, then pickle them for later use.\n",
    "\n",
    "This does not need to be run every time, just when we need to update the MinMaxScaler objects and Normalizer objects in the models folder because we've added a feature or something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [02:41<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire dataset fits in 1.48 GB\n",
      "Number of rows: 52756015\n"
     ]
    }
   ],
   "source": [
    "chunksize = 10 ** 6\n",
    "filename = \"../data/train.csv\"\n",
    "\n",
    "dataset_df = pd.DataFrame()  # main dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "# Pretty progress bar\n",
    "pbar = tqdm(total=len(range(54)))       \n",
    "for index, df_chunk in enumerate(pd.read_csv(filename, chunksize=chunksize)):\n",
    "    pbar.update(1)\n",
    "    dataset_df = pd.concat([dataset_df, preprocess(df_chunk)])\n",
    "pbar.close()\n",
    "\n",
    "size_bytes = dataset_df.memory_usage(deep=True).sum()\n",
    "print(\"Entire dataset fits in {:.2f} GB\".format(size_bytes/1e+9))\n",
    "print(\"Number of rows: {}\".format(dataset_df.count()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fares = dataset_df[\"fare_amount\"]\n",
    "del dataset_df[\"fare_amount\"]\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>-73.844315</td>\n",
       "      <td>40.721317</td>\n",
       "      <td>-73.841614</td>\n",
       "      <td>40.712276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>-74.016045</td>\n",
       "      <td>40.711304</td>\n",
       "      <td>-73.979271</td>\n",
       "      <td>40.782005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-73.982735</td>\n",
       "      <td>40.761269</td>\n",
       "      <td>-73.991241</td>\n",
       "      <td>40.750561</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-73.987129</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991570</td>\n",
       "      <td>40.758091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>-73.968094</td>\n",
       "      <td>40.768009</td>\n",
       "      <td>-73.956657</td>\n",
       "      <td>40.783764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_datetime  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0               17        -73.844315        40.721317         -73.841614   \n",
       "1               16        -74.016045        40.711304         -73.979271   \n",
       "2                0        -73.982735        40.761269         -73.991241   \n",
       "3                4        -73.987129        40.733143         -73.991570   \n",
       "4                7        -73.968094        40.768009         -73.956657   \n",
       "\n",
       "   dropoff_latitude  passenger_count  \n",
       "0         40.712276                1  \n",
       "1         40.782005                1  \n",
       "2         40.750561                2  \n",
       "3         40.758091                1  \n",
       "4         40.783764                1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/envs/jovyan/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int8, float32 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "#Note may not overwrite old pickled files as we dump them, but append instead\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(dataset_df)\n",
    "# then on new data call scaler.transform(data) to scale\n",
    "with open('../models/minmaxscaler.joblib', 'wb') as file:\n",
    "    joblib.dump(scaler, file) \n",
    "del scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We need to normalize on scaled data I think, but I cant fit the scaled df into memory along with the original df\n",
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer = Normalizer().fit(dataset_df)\n",
    "with open('../models/normalizer.joblib', 'wb') as file:\n",
    "    joblib.dump(normalizer, file) \n",
    "del normalizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
